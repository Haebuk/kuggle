{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pubg.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haebuk/kuggle/blob/main/pubg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LSUqzNEmUmE"
      },
      "source": [
        "### Reference\n",
        "- [competition](https://www.kaggle.com/c/pubg-finish-placement-prediction/code?competitionId=10335&sortBy=voteCount\n",
        ")\n",
        "- [1st place discussion](https://www.kaggle.com/c/pubg-finish-placement-prediction/discussion/79161)\n",
        "- [LigthGBM Baseline](https://www.kaggle.com/chocozzz/lightgbm-baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6e2UQhqtmQ3"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxj5Z_vXmUmG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import gc, sys\n",
        "gc.enable()\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import lightgbm as lgb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfCHbwJPthPK"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmwRHXjgmUmH"
      },
      "source": [
        "def feature_engineering(is_train=True, debug=True):\n",
        "    test_idx = None\n",
        "    if is_train:\n",
        "        print('preprocessing train.csv')\n",
        "        if debug == True:\n",
        "            df = pd.read_csv('/content/drive/MyDrive/input/pubg/train_V2.csv', nrow=10000)\n",
        "        else:\n",
        "            df = pd.read_csv('/content/drive/MyDrive/input/pubg/train_V2.csv')\n",
        "\n",
        "        df = df[df['maxPlace'] > 1]\n",
        "    else:\n",
        "        print('processing test.csv')\n",
        "        df = pd.read_csv('/content/drive/MyDrive/input/pubg/test_V2.csv')\n",
        "        test_idx = df.Id\n",
        "\n",
        "    print('remove some columns')\n",
        "    target = 'winPlacePerc'\n",
        "\n",
        "    print('Adding Features')\n",
        "\n",
        "    df['headshotrate'] = df['kills']/df['headshotKills']\n",
        "    df['killStreakrate'] = df['killStreaks']/df['kills']\n",
        "    df['healthitems'] = df['heals'] + df['boosts']\n",
        "    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n",
        "    df['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\n",
        "    df['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\n",
        "    df['distance_over_weapons'] = df['totalDistance'] / df['weaponsAcquired']\n",
        "    df['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\n",
        "    df['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\n",
        "    df['killsPerWalkDistance'] = df['kills'] / df['walkDistance']\n",
        "    df[\"skill\"] = df[\"headshotKills\"] + df[\"roadKills\"]\n",
        "\n",
        "    df[df == np.Inf] = np.NaN\n",
        "    df[df == np.NINF] = np.NaN\n",
        "\n",
        "    print(\"Removing Na's From DF\")\n",
        "    df.fillna(0, inplace=True)\n",
        "\n",
        "    features = list(df.columns)\n",
        "    features.remove('Id')\n",
        "    features.remove('matchId')\n",
        "    features.remove('groupId')\n",
        "    features.remove('matchType')\n",
        "\n",
        "    y = None\n",
        "\n",
        "    if is_train:\n",
        "        print('get target')\n",
        "        y = np.array(df.groupby(['matchId', 'groupId'])[target].agg('mean'), dtype=np.float64)\n",
        "        features.remove(target)\n",
        "\n",
        "    print('get group mean feature')\n",
        "    agg = df.groupby(['matchId', 'groupId'])[features].agg('mean')\n",
        "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
        "    \n",
        "    if is_train:\n",
        "        df_out = agg.reset_index()[['matchId', 'groupId']]\n",
        "    else:\n",
        "        df_out = df[['matchId', 'groupId']]\n",
        "\n",
        "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
        "    df_out = df_out.merge(agg_rank,  suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n",
        "\n",
        "    print('get group max feature')\n",
        "    agg = df.groupby(['matchId', 'groupId'])[features].agg('max')\n",
        "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
        "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
        "    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n",
        "\n",
        "    print('get group min feature')\n",
        "    agg = df.groupby(['matchId', 'groupId'])[features].agg('min')\n",
        "    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n",
        "    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n",
        "    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n",
        "\n",
        "    print('get group size feature')\n",
        "    agg = df.groupby(['matchId', 'groupId']).size().reset_index(name='group_size')\n",
        "    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n",
        "\n",
        "    print('get match mean feature')\n",
        "    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n",
        "    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
        "\n",
        "    print('get match size feature')\n",
        "    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n",
        "    df_out = df_out.merge(agg, how='left', on=['matchId'])\n",
        "\n",
        "    df_out.drop(['matchId', 'groupId'], axis=1, inplace=True)\n",
        "\n",
        "    X = df_out\n",
        "\n",
        "    feature_names = list(df_out.columns)\n",
        "\n",
        "    del df, df_out, agg, agg_rank\n",
        "    gc.collect()\n",
        "\n",
        "    return X, y, feature_names, test_idx"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fSffymLmUmI",
        "outputId": "f5438628-b8c4-4ef2-d5de-91182eb0ceb8"
      },
      "source": [
        "x_train, y_train, train_columns, _ = feature_engineering(True, False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessing train.csv\n",
            "remove some columns\n",
            "Adding Features\n",
            "Removing Na's From DF\n",
            "get target\n",
            "get group mean feature\n",
            "get group max feature\n",
            "get group min feature\n",
            "get group size feature\n",
            "get match mean feature\n",
            "get match size feature\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T96C-8p8mUmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5d7db4-bf82-44bc-b8ce-1b5cd9fcf4fa"
      },
      "source": [
        "x_test, _, _, test_idx = feature_engineering(False, True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing test.csv\n",
            "remove some columns\n",
            "Adding Features\n",
            "Removing Na's From DF\n",
            "get group mean feature\n",
            "get group max feature\n",
            "get group min feature\n",
            "get group size feature\n",
            "get match mean feature\n",
            "get match size feature\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87c8bAsqmUmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1ee74c-1b27-4ba3-b9e5-96e4f1ef66d0"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    start_mem = df.memory_usage().sum()\n",
        "    print(\"Memory usage of dataframe in {:.2f} MB\",format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                # np.iinfo: 정수형 타입의 데이터에 명시한 데이터 타입만큼의 메모리 할당\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "                # np.finfo\n",
        "                elif c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                elif c_min > np.finfo(np.float64).min and c_max < np.finfo(np.float64).max:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "            else:\n",
        "                df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum()\n",
        "    print('Memory Usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df\n",
        "\n",
        "x_train = reduce_mem_usage(x_train)\n",
        "x_test = reduce_mem_usage(x_test)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe in {:.2f} MB 4021060096\n",
            "Memory Usage after optimization is: 1348624632.00 MB\n",
            "Decreased by 66.5%\n",
            "Memory usage of dataframe in {:.2f} MB 3837401216\n",
            "Memory Usage after optimization is: 1113111432.00 MB\n",
            "Decreased by 71.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idWEE1iWH46b"
      },
      "source": [
        "import lightgbm as lgb"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFyv05J33EJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa91f9f-553b-4765-bf4d-1d4d9ea9d1dd"
      },
      "source": [
        "train_index = round(int(x_train.shape[0] * 0.8))\n",
        "tr_X = x_train[:train_index]\n",
        "val_X= x_train[train_index:]\n",
        "tr_y = y_train[:train_index]\n",
        "val_y = y_train[train_index:]\n",
        "gc.collect()\n",
        "\n",
        "# lightgbm model custom\n",
        "def run_lgb(train_X, train_y, val_X, val_y, x_Ztest):\n",
        "    params = {'objective': 'regression',\n",
        "              'metric': 'mae',\n",
        "              'n_estimators': 20000,\n",
        "              'early_stopping_rounds': 200,\n",
        "              'num_leaves': 31,\n",
        "              'learning_rate': 0.05,\n",
        "              'bagging_fraction': 0.7,\n",
        "              'bagging_seed': 0,\n",
        "              'num_threads': 4,\n",
        "              'colsample_bytree': 0.7}\n",
        "\n",
        "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
        "    lgval = lgb.Dataset(val_X, label=val_y)\n",
        "    model = lgb.train(params, lgtrain, valid_sets=[lgtrain, lgval],\n",
        "                      early_stopping_rounds=200, verbose_eval=1000)\n",
        "    pred_test_y = model.predict(x_test, num_iteration=model.best_iteration)\n",
        "    return pred_test_y, model\n",
        "\n",
        "# model training\n",
        "pred_test, model = run_lgb(tr_X, tr_y, val_X, val_y, x_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 2.957690 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 893861\n",
            "[LightGBM] [Info] Number of data points in the train set: 1621395, number of used features: 247\n",
            "[LightGBM] [Info] Start training from score 0.499778\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[1000]\ttraining's l1: 0.0323387\tvalid_1's l1: 0.0386112\n",
            "[2000]\ttraining's l1: 0.0281774\tvalid_1's l1: 0.0380709\n",
            "[3000]\ttraining's l1: 0.0252599\tvalid_1's l1: 0.0378424\n",
            "[4000]\ttraining's l1: 0.0230324\tvalid_1's l1: 0.0377257\n",
            "Early stopping, best iteration is:\n",
            "[4295]\ttraining's l1: 0.0224639\tvalid_1's l1: 0.0377215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwOKmNup6Yys"
      },
      "source": [
        "df_sub = pd.read_csv('/content/drive/MyDrive/input/pubg/sample_submission_V2.csv')\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/input/pubg/test_V2.csv')\n",
        "df_sub['winPlacePerc'] = pred_test\n",
        "# 몇 가지 열 복원\n",
        "df_sub = df_sub.merge(df_test[['Id', 'matchId', 'groupId', 'maxPlace', 'numGroups']],\n",
        "                      on='Id', how='left')\n",
        "\n",
        "#\n",
        "df_sub_group = df_sub.groupby(['matchId', 'groupId']).first().reset_index()\n",
        "df_sub_group['rank'] = df_sub.groupby(['matchId'])['winPlacePerc'].rank()\n",
        "df_sub_group = df_sub_group.merge(\n",
        "    df_sub_group.groupby('matchId')['rank'].max().to_frame('max_rank').reset_index(),\n",
        "    on='matchId', how='left'\n",
        ")\n",
        "df_sub_group['adjusted_perc'] = (df_sub_group['rank'] - 1) / (df_sub_group['numGroups'] - 1)\n",
        "\n",
        "df_sub = df_sub.merge(df_sub_group[['adjusted_perc', 'matchId', 'groupId']],\n",
        "                      on = ['matchId', 'groupId'], how='left')\n",
        "df_sub['winPlacePerc'] = df_sub['adjusted_perc']\n",
        "\n",
        "df_sub.loc[df_sub.maxPlace == 0, 'winPlacePerc'] = 0\n",
        "df_sub.loc[df_sub.maxPlace == 1, 'winPlacePerc'] = 1\n",
        "\n",
        "subset = df_sub.loc[df_sub.maxPlace > 1]\n",
        "gap = 1.0 / (subset.maxPlace.values - 1)\n",
        "new_perc = np.around(subset.winPlacePerc.values / gap) * gap\n",
        "df_sub.loc[df_sub.maxPlace > 1, 'winPlacePerc'] = new_perc\n",
        "\n",
        "df_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 1), 'winPlacePerc'] = 0\n",
        "assert df_sub['winPlacePerc'].isnull().sum() == 0\n",
        "\n",
        "df_sub[['Id', 'winPlacePerc']].to_csv('submission_adjusted.csv', index=False)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSIMet3ew4XZ"
      },
      "source": [
        "![image](https://user-images.githubusercontent.com/68543150/119942983-62b28680-bfcd-11eb-8894-e61e85cdf9e5.png)\n"
      ]
    }
  ]
}