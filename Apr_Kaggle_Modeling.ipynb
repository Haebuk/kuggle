{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apr_Kaggle_Modeling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOMZwFBbi3/0Dizpxz1VtXW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haebuk/kuggle/blob/main/Apr_Kaggle_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWNQV240FTA5"
      },
      "source": [
        "# 2021 Apr Modeling\n",
        "- [\n",
        "N3. [TPS April 21] LightAutoML starter](https://www.kaggle.com/alexryzhkov/n3-tps-april-21-lightautoml-starter)\n",
        "- [\n",
        "TPS Apr 2021 pseudo labeling/voting ensemble](https://www.kaggle.com/hiro5299834/tps-apr-2021-pseudo-labeling-voting-ensemble/notebook?select=pseudo_label.csv )\n",
        "- [Pseudolabelling - Tips and tricks](https://www.kaggle.com/c/tabular-playground-series-apr-2021/discussion/231738)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG3fMCQUJDO5"
      },
      "source": [
        "## Colab Softwrap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7ovzk0GEIqKe",
        "outputId": "7c371b9b-2005-41dc-995d-b8d8fa58ecb7"
      },
      "source": [
        "# colab softwrap\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnLB6u12FeN-"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oGhOdt0OFuxZ",
        "outputId": "666dd06d-971f-41aa-d594-094acd3d480a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression as lr\n",
        "!pip install -q lightgbm==3.2.1\n",
        "import lightgbm as lgb\n",
        "!pip install -q catboost\n",
        "import catboost as ctb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "\n",
        "import graphviz\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mmMjfKbfGN0e",
        "outputId": "678acc42-05c6-41e9-9bd7-328ac7aec0ed"
      },
      "source": [
        "TARGET = 'Survived'\n",
        "\n",
        "N_ESTIMATORS = 1000\n",
        "N_SPLIT = 10\n",
        "SEED = 2021\n",
        "EARLY_STOPPING_ROUNDS = 100 \n",
        "VERBOSE = 100"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0VyEnSRGGx_E",
        "outputId": "544861aa-04f3-486a-9c40-921b575165b5"
      },
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(SEED)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWxKGbd9HKpR"
      },
      "source": [
        "## Git Clone & Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuYQFujBG7AF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ff06038-42ce-48cb-cf2a-fcb8aed9ebf2"
      },
      "source": [
        "!git clone https://github.com/Haebuk/kuggle.git\n",
        "PATH = '/content/kuggle/9,10주차/input/'\n",
        "train_df = pd.read_csv(PATH+'train.csv')\n",
        "test_df = pd.read_csv(PATH+'test.csv')\n",
        "submission_df = pd.read_csv(PATH+'sample_submission.csv')\n",
        "\n",
        "all_df = pd.concat([train_df, test_df]).reset_index(drop=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'kuggle' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYvlQw_ZHn_Z"
      },
      "source": [
        "## Filling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "sWMTxsxvMfVD",
        "outputId": "ed6b67ea-a506-44fe-f33d-d85667233252"
      },
      "source": [
        "all_df.tail()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>199995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Cash, Cheryle</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7686</td>\n",
              "      <td>10.12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>199996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Brown, Howard</td>\n",
              "      <td>male</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13004</td>\n",
              "      <td>68.31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>199997</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Lightfoot, Cameron</td>\n",
              "      <td>male</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4383317</td>\n",
              "      <td>10.87</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>199998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Jacobsen, Margaret</td>\n",
              "      <td>female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>PC 26988</td>\n",
              "      <td>29.68</td>\n",
              "      <td>B20828</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>199999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Fishback, Joanna</td>\n",
              "      <td>female</td>\n",
              "      <td>41.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>PC 41824</td>\n",
              "      <td>195.41</td>\n",
              "      <td>E13345</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PassengerId  Survived  Pclass  ...    Fare   Cabin  Embarked\n",
              "199995       199995       NaN       3  ...   10.12     NaN         Q\n",
              "199996       199996       NaN       1  ...   68.31     NaN         S\n",
              "199997       199997       NaN       3  ...   10.87     NaN         S\n",
              "199998       199998       NaN       1  ...   29.68  B20828         C\n",
              "199999       199999       NaN       1  ...  195.41  E13345         C\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "6o8MDiEsKfSX",
        "outputId": "e5f5cba2-90ab-4886-a7cc-336b60d28435"
      },
      "source": [
        "for col in all_df.columns:\n",
        "    print(col, all_df[col].isnull().sum())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "PassengerId 0\n",
            "Survived 100000\n",
            "Pclass 0\n",
            "Name 0\n",
            "Sex 0\n",
            "Age 6779\n",
            "SibSp 0\n",
            "Parch 0\n",
            "Ticket 9804\n",
            "Fare 267\n",
            "Cabin 138697\n",
            "Embarked 527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "GKNoJbNuH4kU",
        "outputId": "fac7cd04-097c-4615-c3d1-7158a80c17df"
      },
      "source": [
        "# 연령 결측값 -> 평균으로 대체\n",
        "all_df['Age'] = all_df['Age'].fillna(all_df['Age'].mean())\n",
        "\n",
        "# 선실 결측값 -> X로 대체 및 나머지는 첫글자로 대체\n",
        "all_df['Cabin'] = all_df['Cabin'].fillna('X').map(lambda x: x[0].strip())\n",
        "\n",
        "# 티켓 결측값 -> X로 대체 및 나머지는 첫 어절로 대체\n",
        "all_df['Ticket'] = all_df['Ticket'].fillna('X').\\\n",
        "map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n",
        "\n",
        "# 요금 결측값 -> Pclass의 중위수로 대체 후 로그변환(정규화)\n",
        "fare_map = all_df[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n",
        "all_df['Fare'] = all_df['Fare'].fillna(all_df['Pclass'].map(fare_map['Fare']))\n",
        "all_df['Fare'] = np.log1p(all_df['Fare'])\n",
        "\n",
        "# 탑승항구 결측값 -> X로 대체\n",
        "all_df['Embarked'] = all_df['Embarked'].fillna('X')\n",
        "\n",
        "# 성을 제외한 이름만 추출\n",
        "all_df['Name'] = all_df['Name'].map(lambda x: x.split(',')[0])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cO8x1GCNCfk"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "tzQyUa0VHwbG",
        "outputId": "697a06e5-8ee5-4ec2-c925-b8c915337cad"
      },
      "source": [
        "label_cols = ['Name', 'Ticket', 'Sex']\n",
        "onehot_cols = ['Cabin', 'Embarked']\n",
        "numerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "COtcNVoJNhuD",
        "outputId": "9e0a420f-2947-47c4-fc71-852cd662f0de"
      },
      "source": [
        "def label_encoder(c):\n",
        "    le = LabelEncoder()\n",
        "    return le.fit_transform(c)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "onehot_encoded_df = pd.get_dummies(all_df[onehot_cols])\n",
        "label_encoded_df = all_df[label_cols].apply(label_encoder)\n",
        "numerical_df = pd.DataFrame(scaler.fit_transform(all_df[numerical_cols]), \n",
        "                            columns=numerical_cols)\n",
        "target_df = all_df[TARGET]\n",
        "\n",
        "all_df = pd.concat([numerical_df, label_encoded_df, onehot_encoded_df, target_df],\\\n",
        "                   axis=1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a7V7ocBtduDc",
        "outputId": "b9b79918-652a-4fc4-f2d4-725063967a81"
      },
      "source": [
        "train_df2 = all_df[:train_df.shape[0]]\n",
        "test_df2 = all_df[train_df.shape[0]:]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKbDMU4SFEKG"
      },
      "source": [
        "## Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jNn83Q_VFHAF",
        "outputId": "577c13ec-ad94-460c-da8f-1c824681750f"
      },
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "X_test = test_df2.drop(TARGET, axis=1)\n",
        "skf = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df2, train_df2[TARGET])):\n",
        "    print(f'===== FOLD {fold} =====')\n",
        "\n",
        "    X_train, y_train = train_df2.iloc[train_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[train_idx][TARGET]\n",
        "    X_valid, y_valid = train_df2.iloc[valid_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[valid_idx][TARGET]\n",
        "\n",
        "    model = lr(max_iter=300, verbose=VERBOSE)\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    lr_val = model.predict(X_valid)\n",
        "    lr_val = [1 if v >= 0.5 else 0 for v in lr_val]\n",
        "    lr_preds = model.predict(X_test)\n",
        "\n",
        "    \n",
        "    # 확률이 0.5보다 크면 1, 작으면 0으로 분류\n",
        "    acc_score = accuracy_score(y_valid, lr_val)\n",
        "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "===== FOLD 0 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s finished\n",
            "===== ACCURACY SCORE 0.761900 =====\n",
            "\n",
            "===== FOLD 1 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s finished\n",
            "===== ACCURACY SCORE 0.773500 =====\n",
            "\n",
            "===== FOLD 2 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s finished\n",
            "===== ACCURACY SCORE 0.769900 =====\n",
            "\n",
            "===== FOLD 3 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s finished\n",
            "===== ACCURACY SCORE 0.768700 =====\n",
            "\n",
            "===== FOLD 4 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s finished\n",
            "===== ACCURACY SCORE 0.758300 =====\n",
            "\n",
            "===== FOLD 5 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
            "===== ACCURACY SCORE 0.685500 =====\n",
            "\n",
            "===== FOLD 6 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
            "===== ACCURACY SCORE 0.688800 =====\n",
            "\n",
            "===== FOLD 7 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s finished\n",
            "===== ACCURACY SCORE 0.772600 =====\n",
            "\n",
            "===== FOLD 8 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s finished\n",
            "===== ACCURACY SCORE 0.767800 =====\n",
            "\n",
            "===== FOLD 9 =====\n",
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s finished\n",
            "===== ACCURACY SCORE 0.765200 =====\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee42ZGlRPOhA"
      },
      "source": [
        "## LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ipvauXRYPSRP",
        "outputId": "55ad3641-4bf7-44fe-e55c-ead4d1e90479"
      },
      "source": [
        "params = {\n",
        "    'metric': 'binary_logloss',\n",
        "    'n_estimators': N_ESTIMATORS,\n",
        "    'objective': 'binary',\n",
        "    'random_state': SEED,\n",
        "    'learning_rate': 0.01,\n",
        "    'min_child_samples': 150,\n",
        "    'reg_alpha': 3e-5,\n",
        "    'reg_lambda': 9e-2,\n",
        "    'num_leaves': 20,\n",
        "    'max_depth': 16,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'subsample': 0.8,\n",
        "    'subsample_freq': 2,\n",
        "    'max_bin': 240,\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EYvD38FQPYkl",
        "outputId": "d8f949e0-d7f8-43fc-f6a0-fddcd6d683f3"
      },
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "X_test = test_df2.drop(TARGET, axis=1)\n",
        "skf = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df2, train_df2[TARGET])):\n",
        "    print(f'===== FOLD {fold} =====')\n",
        "\n",
        "    X_train, y_train = train_df2.iloc[train_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[train_idx][TARGET]\n",
        "    X_valid, y_valid = train_df2.iloc[valid_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[valid_idx][TARGET]\n",
        "\n",
        "    pre_model = lgb.LGBMRegressor(**params)\n",
        "    pre_model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
        "        early_stopping_rounds = EARLY_STOPPING_ROUNDS,\n",
        "        verbose = VERBOSE\n",
        "    )\n",
        "\n",
        "    params2 = params.copy()\n",
        "    params2['learning_rate'] = params['learning_rate'] * 0.1\n",
        "    model = lgb.LGBMRegressor(**params2)\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
        "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
        "        verbose=VERBOSE,\n",
        "        init_model=pre_model\n",
        "    )\n",
        "\n",
        "    # feature importance\n",
        "    fi_tmp = pd.DataFrame()\n",
        "    fi_tmp['feature'] = model.feature_name_\n",
        "    fi_tmp['importance'] = model.feature_importances_\n",
        "    fi_tmp['fold'] = fold\n",
        "    fi_tmp['seed'] = SEED\n",
        "    feature_importances = feature_importances.append(fi_tmp)\n",
        "    \n",
        "    lgb_val = model.predict(X_valid)\n",
        "    lgb_val = [1 if v >= 0.5 else 0 for v in lgb_val]\n",
        "    lgb_preds = model.predict(X_test)\n",
        "\n",
        "    \n",
        "    # 확률이 0.5보다 크면 1, 작으면 0으로 분류\n",
        "    acc_score = accuracy_score(y_valid, lgb_val)\n",
        "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "===== FOLD 0 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.52195\tvalid_1's binary_logloss: 0.523998\n",
            "[200]\ttraining's binary_logloss: 0.484826\tvalid_1's binary_logloss: 0.488637\n",
            "[300]\ttraining's binary_logloss: 0.473859\tvalid_1's binary_logloss: 0.479154\n",
            "[400]\ttraining's binary_logloss: 0.469461\tvalid_1's binary_logloss: 0.475771\n",
            "[500]\ttraining's binary_logloss: 0.467025\tvalid_1's binary_logloss: 0.474104\n",
            "[600]\ttraining's binary_logloss: 0.465386\tvalid_1's binary_logloss: 0.473314\n",
            "[700]\ttraining's binary_logloss: 0.464096\tvalid_1's binary_logloss: 0.472792\n",
            "[800]\ttraining's binary_logloss: 0.463023\tvalid_1's binary_logloss: 0.472523\n",
            "[900]\ttraining's binary_logloss: 0.462084\tvalid_1's binary_logloss: 0.47237\n",
            "[1000]\ttraining's binary_logloss: 0.461183\tvalid_1's binary_logloss: 0.472227\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.461183\tvalid_1's binary_logloss: 0.472227\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461094\tvalid_1's binary_logloss: 0.472222\n",
            "[1200]\ttraining's binary_logloss: 0.461009\tvalid_1's binary_logloss: 0.472211\n",
            "[1300]\ttraining's binary_logloss: 0.460925\tvalid_1's binary_logloss: 0.472204\n",
            "[1400]\ttraining's binary_logloss: 0.460844\tvalid_1's binary_logloss: 0.472201\n",
            "Early stopping, best iteration is:\n",
            "[1390]\ttraining's binary_logloss: 0.460852\tvalid_1's binary_logloss: 0.4722\n",
            "===== ACCURACY SCORE 0.779000 =====\n",
            "\n",
            "===== FOLD 1 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522704\tvalid_1's binary_logloss: 0.51918\n",
            "[200]\ttraining's binary_logloss: 0.485975\tvalid_1's binary_logloss: 0.481349\n",
            "[300]\ttraining's binary_logloss: 0.475115\tvalid_1's binary_logloss: 0.470225\n",
            "[400]\ttraining's binary_logloss: 0.47075\tvalid_1's binary_logloss: 0.466134\n",
            "[500]\ttraining's binary_logloss: 0.468332\tvalid_1's binary_logloss: 0.464304\n",
            "[600]\ttraining's binary_logloss: 0.466676\tvalid_1's binary_logloss: 0.4633\n",
            "[700]\ttraining's binary_logloss: 0.465409\tvalid_1's binary_logloss: 0.462813\n",
            "[800]\ttraining's binary_logloss: 0.464352\tvalid_1's binary_logloss: 0.46249\n",
            "[900]\ttraining's binary_logloss: 0.463402\tvalid_1's binary_logloss: 0.462298\n",
            "[1000]\ttraining's binary_logloss: 0.462511\tvalid_1's binary_logloss: 0.462152\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.462511\tvalid_1's binary_logloss: 0.462152\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.462424\tvalid_1's binary_logloss: 0.462135\n",
            "[1200]\ttraining's binary_logloss: 0.462342\tvalid_1's binary_logloss: 0.462124\n",
            "[1300]\ttraining's binary_logloss: 0.462258\tvalid_1's binary_logloss: 0.462108\n",
            "[1400]\ttraining's binary_logloss: 0.462174\tvalid_1's binary_logloss: 0.462093\n",
            "[1500]\ttraining's binary_logloss: 0.462089\tvalid_1's binary_logloss: 0.462085\n",
            "[1600]\ttraining's binary_logloss: 0.462005\tvalid_1's binary_logloss: 0.462073\n",
            "[1700]\ttraining's binary_logloss: 0.461922\tvalid_1's binary_logloss: 0.462058\n",
            "[1800]\ttraining's binary_logloss: 0.461837\tvalid_1's binary_logloss: 0.462044\n",
            "[1900]\ttraining's binary_logloss: 0.461756\tvalid_1's binary_logloss: 0.462034\n",
            "[2000]\ttraining's binary_logloss: 0.461675\tvalid_1's binary_logloss: 0.462022\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.461675\tvalid_1's binary_logloss: 0.462022\n",
            "===== ACCURACY SCORE 0.788600 =====\n",
            "\n",
            "===== FOLD 2 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522037\tvalid_1's binary_logloss: 0.52336\n",
            "[200]\ttraining's binary_logloss: 0.485134\tvalid_1's binary_logloss: 0.487293\n",
            "[300]\ttraining's binary_logloss: 0.474239\tvalid_1's binary_logloss: 0.476999\n",
            "[400]\ttraining's binary_logloss: 0.469852\tvalid_1's binary_logloss: 0.473221\n",
            "[500]\ttraining's binary_logloss: 0.467434\tvalid_1's binary_logloss: 0.471488\n",
            "[600]\ttraining's binary_logloss: 0.465755\tvalid_1's binary_logloss: 0.470694\n",
            "[700]\ttraining's binary_logloss: 0.46447\tvalid_1's binary_logloss: 0.470194\n",
            "[800]\ttraining's binary_logloss: 0.463379\tvalid_1's binary_logloss: 0.469959\n",
            "[900]\ttraining's binary_logloss: 0.46241\tvalid_1's binary_logloss: 0.469866\n",
            "Early stopping, best iteration is:\n",
            "[868]\ttraining's binary_logloss: 0.46272\tvalid_1's binary_logloss: 0.46985\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[900]\ttraining's binary_logloss: 0.46269\tvalid_1's binary_logloss: 0.469848\n",
            "[1000]\ttraining's binary_logloss: 0.462597\tvalid_1's binary_logloss: 0.469837\n",
            "[1100]\ttraining's binary_logloss: 0.462507\tvalid_1's binary_logloss: 0.469835\n",
            "[1200]\ttraining's binary_logloss: 0.462418\tvalid_1's binary_logloss: 0.469825\n",
            "[1300]\ttraining's binary_logloss: 0.462328\tvalid_1's binary_logloss: 0.469814\n",
            "[1400]\ttraining's binary_logloss: 0.462236\tvalid_1's binary_logloss: 0.469806\n",
            "[1500]\ttraining's binary_logloss: 0.462147\tvalid_1's binary_logloss: 0.469804\n",
            "[1600]\ttraining's binary_logloss: 0.462055\tvalid_1's binary_logloss: 0.469788\n",
            "[1700]\ttraining's binary_logloss: 0.461964\tvalid_1's binary_logloss: 0.469778\n",
            "[1800]\ttraining's binary_logloss: 0.461877\tvalid_1's binary_logloss: 0.469778\n",
            "Early stopping, best iteration is:\n",
            "[1722]\ttraining's binary_logloss: 0.461944\tvalid_1's binary_logloss: 0.469776\n",
            "===== ACCURACY SCORE 0.783600 =====\n",
            "\n",
            "===== FOLD 3 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.521861\tvalid_1's binary_logloss: 0.525059\n",
            "[200]\ttraining's binary_logloss: 0.484797\tvalid_1's binary_logloss: 0.489376\n",
            "[300]\ttraining's binary_logloss: 0.473825\tvalid_1's binary_logloss: 0.479643\n",
            "[400]\ttraining's binary_logloss: 0.469374\tvalid_1's binary_logloss: 0.476104\n",
            "[500]\ttraining's binary_logloss: 0.466966\tvalid_1's binary_logloss: 0.474579\n",
            "[600]\ttraining's binary_logloss: 0.465295\tvalid_1's binary_logloss: 0.473908\n",
            "[700]\ttraining's binary_logloss: 0.464016\tvalid_1's binary_logloss: 0.473556\n",
            "[800]\ttraining's binary_logloss: 0.462937\tvalid_1's binary_logloss: 0.473298\n",
            "[900]\ttraining's binary_logloss: 0.462013\tvalid_1's binary_logloss: 0.473216\n",
            "[1000]\ttraining's binary_logloss: 0.461104\tvalid_1's binary_logloss: 0.473122\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.461104\tvalid_1's binary_logloss: 0.473122\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461017\tvalid_1's binary_logloss: 0.473129\n",
            "Early stopping, best iteration is:\n",
            "[1021]\ttraining's binary_logloss: 0.461086\tvalid_1's binary_logloss: 0.473122\n",
            "===== ACCURACY SCORE 0.782800 =====\n",
            "\n",
            "===== FOLD 4 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.52201\tvalid_1's binary_logloss: 0.524383\n",
            "[200]\ttraining's binary_logloss: 0.485011\tvalid_1's binary_logloss: 0.48873\n",
            "[300]\ttraining's binary_logloss: 0.474128\tvalid_1's binary_logloss: 0.47843\n",
            "[400]\ttraining's binary_logloss: 0.469787\tvalid_1's binary_logloss: 0.474651\n",
            "[500]\ttraining's binary_logloss: 0.467342\tvalid_1's binary_logloss: 0.472865\n",
            "[600]\ttraining's binary_logloss: 0.465677\tvalid_1's binary_logloss: 0.471931\n",
            "[700]\ttraining's binary_logloss: 0.46442\tvalid_1's binary_logloss: 0.471467\n",
            "[800]\ttraining's binary_logloss: 0.463335\tvalid_1's binary_logloss: 0.471189\n",
            "[900]\ttraining's binary_logloss: 0.462388\tvalid_1's binary_logloss: 0.471068\n",
            "[1000]\ttraining's binary_logloss: 0.461492\tvalid_1's binary_logloss: 0.471036\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.461492\tvalid_1's binary_logloss: 0.471036\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461405\tvalid_1's binary_logloss: 0.471027\n",
            "[1200]\ttraining's binary_logloss: 0.461318\tvalid_1's binary_logloss: 0.471022\n",
            "[1300]\ttraining's binary_logloss: 0.461231\tvalid_1's binary_logloss: 0.471011\n",
            "[1400]\ttraining's binary_logloss: 0.461146\tvalid_1's binary_logloss: 0.471005\n",
            "[1500]\ttraining's binary_logloss: 0.461061\tvalid_1's binary_logloss: 0.471002\n",
            "[1600]\ttraining's binary_logloss: 0.46098\tvalid_1's binary_logloss: 0.470992\n",
            "[1700]\ttraining's binary_logloss: 0.460895\tvalid_1's binary_logloss: 0.470987\n",
            "[1800]\ttraining's binary_logloss: 0.46081\tvalid_1's binary_logloss: 0.470985\n",
            "[1900]\ttraining's binary_logloss: 0.460732\tvalid_1's binary_logloss: 0.47098\n",
            "[2000]\ttraining's binary_logloss: 0.46065\tvalid_1's binary_logloss: 0.470982\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.46065\tvalid_1's binary_logloss: 0.470982\n",
            "===== ACCURACY SCORE 0.780400 =====\n",
            "\n",
            "===== FOLD 5 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522394\tvalid_1's binary_logloss: 0.522067\n",
            "[200]\ttraining's binary_logloss: 0.485488\tvalid_1's binary_logloss: 0.485128\n",
            "[300]\ttraining's binary_logloss: 0.474652\tvalid_1's binary_logloss: 0.47446\n",
            "[400]\ttraining's binary_logloss: 0.470278\tvalid_1's binary_logloss: 0.470521\n",
            "[500]\ttraining's binary_logloss: 0.467829\tvalid_1's binary_logloss: 0.468664\n",
            "[600]\ttraining's binary_logloss: 0.466182\tvalid_1's binary_logloss: 0.467694\n",
            "[700]\ttraining's binary_logloss: 0.464921\tvalid_1's binary_logloss: 0.467171\n",
            "[800]\ttraining's binary_logloss: 0.463883\tvalid_1's binary_logloss: 0.466879\n",
            "[900]\ttraining's binary_logloss: 0.462916\tvalid_1's binary_logloss: 0.466704\n",
            "[1000]\ttraining's binary_logloss: 0.462041\tvalid_1's binary_logloss: 0.466565\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.462041\tvalid_1's binary_logloss: 0.466565\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461953\tvalid_1's binary_logloss: 0.466547\n",
            "[1200]\ttraining's binary_logloss: 0.461867\tvalid_1's binary_logloss: 0.466533\n",
            "[1300]\ttraining's binary_logloss: 0.461782\tvalid_1's binary_logloss: 0.466529\n",
            "[1400]\ttraining's binary_logloss: 0.461697\tvalid_1's binary_logloss: 0.466509\n",
            "[1500]\ttraining's binary_logloss: 0.461613\tvalid_1's binary_logloss: 0.466499\n",
            "[1600]\ttraining's binary_logloss: 0.461526\tvalid_1's binary_logloss: 0.466485\n",
            "[1700]\ttraining's binary_logloss: 0.461442\tvalid_1's binary_logloss: 0.466475\n",
            "[1800]\ttraining's binary_logloss: 0.46136\tvalid_1's binary_logloss: 0.466469\n",
            "[1900]\ttraining's binary_logloss: 0.461277\tvalid_1's binary_logloss: 0.46646\n",
            "[2000]\ttraining's binary_logloss: 0.461195\tvalid_1's binary_logloss: 0.466455\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.461195\tvalid_1's binary_logloss: 0.466455\n",
            "===== ACCURACY SCORE 0.785000 =====\n",
            "\n",
            "===== FOLD 6 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.52284\tvalid_1's binary_logloss: 0.518276\n",
            "[200]\ttraining's binary_logloss: 0.486072\tvalid_1's binary_logloss: 0.479885\n",
            "[300]\ttraining's binary_logloss: 0.475282\tvalid_1's binary_logloss: 0.468872\n",
            "[400]\ttraining's binary_logloss: 0.47092\tvalid_1's binary_logloss: 0.46473\n",
            "[500]\ttraining's binary_logloss: 0.468545\tvalid_1's binary_logloss: 0.462797\n",
            "[600]\ttraining's binary_logloss: 0.466879\tvalid_1's binary_logloss: 0.461706\n",
            "[700]\ttraining's binary_logloss: 0.465663\tvalid_1's binary_logloss: 0.461122\n",
            "[800]\ttraining's binary_logloss: 0.464624\tvalid_1's binary_logloss: 0.460814\n",
            "[900]\ttraining's binary_logloss: 0.463697\tvalid_1's binary_logloss: 0.460658\n",
            "[1000]\ttraining's binary_logloss: 0.462815\tvalid_1's binary_logloss: 0.460485\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.462815\tvalid_1's binary_logloss: 0.460485\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.462729\tvalid_1's binary_logloss: 0.460469\n",
            "[1200]\ttraining's binary_logloss: 0.462641\tvalid_1's binary_logloss: 0.460455\n",
            "[1300]\ttraining's binary_logloss: 0.462555\tvalid_1's binary_logloss: 0.460446\n",
            "[1400]\ttraining's binary_logloss: 0.462475\tvalid_1's binary_logloss: 0.460429\n",
            "[1500]\ttraining's binary_logloss: 0.462392\tvalid_1's binary_logloss: 0.460407\n",
            "[1600]\ttraining's binary_logloss: 0.46231\tvalid_1's binary_logloss: 0.460397\n",
            "[1700]\ttraining's binary_logloss: 0.462228\tvalid_1's binary_logloss: 0.460383\n",
            "[1800]\ttraining's binary_logloss: 0.462146\tvalid_1's binary_logloss: 0.460371\n",
            "[1900]\ttraining's binary_logloss: 0.462069\tvalid_1's binary_logloss: 0.46036\n",
            "[2000]\ttraining's binary_logloss: 0.461988\tvalid_1's binary_logloss: 0.460348\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.461988\tvalid_1's binary_logloss: 0.460348\n",
            "===== ACCURACY SCORE 0.785900 =====\n",
            "\n",
            "===== FOLD 7 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522559\tvalid_1's binary_logloss: 0.519849\n",
            "[200]\ttraining's binary_logloss: 0.485761\tvalid_1's binary_logloss: 0.482267\n",
            "[300]\ttraining's binary_logloss: 0.47484\tvalid_1's binary_logloss: 0.471547\n",
            "[400]\ttraining's binary_logloss: 0.470435\tvalid_1's binary_logloss: 0.467685\n",
            "[500]\ttraining's binary_logloss: 0.468023\tvalid_1's binary_logloss: 0.465999\n",
            "[600]\ttraining's binary_logloss: 0.466297\tvalid_1's binary_logloss: 0.465284\n",
            "[700]\ttraining's binary_logloss: 0.465021\tvalid_1's binary_logloss: 0.465012\n",
            "[800]\ttraining's binary_logloss: 0.463949\tvalid_1's binary_logloss: 0.464953\n",
            "Early stopping, best iteration is:\n",
            "[731]\ttraining's binary_logloss: 0.464674\tvalid_1's binary_logloss: 0.464943\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[800]\ttraining's binary_logloss: 0.464598\tvalid_1's binary_logloss: 0.464942\n",
            "Early stopping, best iteration is:\n",
            "[743]\ttraining's binary_logloss: 0.464661\tvalid_1's binary_logloss: 0.46494\n",
            "===== ACCURACY SCORE 0.788800 =====\n",
            "\n",
            "===== FOLD 8 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.521548\tvalid_1's binary_logloss: 0.526133\n",
            "[200]\ttraining's binary_logloss: 0.484561\tvalid_1's binary_logloss: 0.491406\n",
            "[300]\ttraining's binary_logloss: 0.473623\tvalid_1's binary_logloss: 0.481902\n",
            "[400]\ttraining's binary_logloss: 0.469182\tvalid_1's binary_logloss: 0.478545\n",
            "[500]\ttraining's binary_logloss: 0.466746\tvalid_1's binary_logloss: 0.477057\n",
            "[600]\ttraining's binary_logloss: 0.46508\tvalid_1's binary_logloss: 0.47628\n",
            "[700]\ttraining's binary_logloss: 0.463803\tvalid_1's binary_logloss: 0.475882\n",
            "[800]\ttraining's binary_logloss: 0.462753\tvalid_1's binary_logloss: 0.475661\n",
            "[900]\ttraining's binary_logloss: 0.46183\tvalid_1's binary_logloss: 0.475518\n",
            "[1000]\ttraining's binary_logloss: 0.460941\tvalid_1's binary_logloss: 0.47539\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.460941\tvalid_1's binary_logloss: 0.47539\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.460853\tvalid_1's binary_logloss: 0.475376\n",
            "[1200]\ttraining's binary_logloss: 0.460767\tvalid_1's binary_logloss: 0.475366\n",
            "[1300]\ttraining's binary_logloss: 0.460682\tvalid_1's binary_logloss: 0.475361\n",
            "[1400]\ttraining's binary_logloss: 0.460595\tvalid_1's binary_logloss: 0.475355\n",
            "[1500]\ttraining's binary_logloss: 0.46051\tvalid_1's binary_logloss: 0.475339\n",
            "[1600]\ttraining's binary_logloss: 0.460426\tvalid_1's binary_logloss: 0.475333\n",
            "[1700]\ttraining's binary_logloss: 0.460339\tvalid_1's binary_logloss: 0.475328\n",
            "[1800]\ttraining's binary_logloss: 0.460256\tvalid_1's binary_logloss: 0.475324\n",
            "[1900]\ttraining's binary_logloss: 0.460176\tvalid_1's binary_logloss: 0.475321\n",
            "[2000]\ttraining's binary_logloss: 0.460095\tvalid_1's binary_logloss: 0.475308\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's binary_logloss: 0.460095\tvalid_1's binary_logloss: 0.475308\n",
            "===== ACCURACY SCORE 0.777400 =====\n",
            "\n",
            "===== FOLD 9 =====\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\ttraining's binary_logloss: 0.522051\tvalid_1's binary_logloss: 0.524528\n",
            "[200]\ttraining's binary_logloss: 0.485098\tvalid_1's binary_logloss: 0.488465\n",
            "[300]\ttraining's binary_logloss: 0.474082\tvalid_1's binary_logloss: 0.478293\n",
            "[400]\ttraining's binary_logloss: 0.469621\tvalid_1's binary_logloss: 0.474788\n",
            "[500]\ttraining's binary_logloss: 0.467216\tvalid_1's binary_logloss: 0.473346\n",
            "[600]\ttraining's binary_logloss: 0.465546\tvalid_1's binary_logloss: 0.472598\n",
            "[700]\ttraining's binary_logloss: 0.464263\tvalid_1's binary_logloss: 0.472206\n",
            "[800]\ttraining's binary_logloss: 0.463152\tvalid_1's binary_logloss: 0.472047\n",
            "[900]\ttraining's binary_logloss: 0.462188\tvalid_1's binary_logloss: 0.472021\n",
            "[1000]\ttraining's binary_logloss: 0.46129\tvalid_1's binary_logloss: 0.471981\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's binary_logloss: 0.46129\tvalid_1's binary_logloss: 0.471981\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[1100]\ttraining's binary_logloss: 0.461201\tvalid_1's binary_logloss: 0.471992\n",
            "Early stopping, best iteration is:\n",
            "[1002]\ttraining's binary_logloss: 0.461288\tvalid_1's binary_logloss: 0.471981\n",
            "===== ACCURACY SCORE 0.777600 =====\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w-pt51lqvji"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "x7v8OE6HqvRB",
        "outputId": "60f2b152-6756-4b8d-a783-7bc37af9b4ec"
      },
      "source": [
        "order = list(feature_importances.groupby('feature').mean().\\\n",
        "             sort_values('importance', ascending=False).index)\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importances, order=order)\n",
        "plt.title('{} importance'.format('LGBMRegressor'))\n",
        "plt.tight_layout()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEGugBkPrNyk"
      },
      "source": [
        "## CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4Pe28sfHrRwq",
        "outputId": "079774a9-1ab3-4eca-9d8a-2015e732bb42"
      },
      "source": [
        "params = {\n",
        "    'bootstrap_type': 'Poisson',\n",
        "    'loss_function': 'Logloss',\n",
        "    'eval_metric': 'Logloss',\n",
        "    'random_seed': SEED,\n",
        "    'task_type': 'GPU',\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.01,\n",
        "    'n_estimators': N_ESTIMATORS,\n",
        "    'max_bin': 280,\n",
        "    'min_data_in_leaf': 64,\n",
        "    'l2_leaf_reg': 0.01,\n",
        "    'subsample': 0.8\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FB3NWFJ3rTGC",
        "outputId": "6d17b397-4e33-4eaa-fb00-cdcda71ee667"
      },
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df2, train_df2[TARGET])):\n",
        "    print(f'===== FOLD {fold} =====')\n",
        "\n",
        "    X_train, y_train = train_df2.iloc[train_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[train_idx][TARGET]\n",
        "    X_valid, y_valid = train_df2.iloc[valid_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[valid_idx][TARGET]\n",
        "\n",
        "    model = ctb.CatBoostClassifier(**params)\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        use_best_model = True,\n",
        "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
        "        verbose=VERBOSE,\n",
        "    )\n",
        "\n",
        "    # feature importance\n",
        "    fi_tmp = pd.DataFrame()\n",
        "    fi_tmp['feature'] = X_test.columns.to_list()\n",
        "    fi_tmp['importance'] = model.get_feature_importance()\n",
        "    fi_tmp['fold'] = fold\n",
        "    fi_tmp['seed'] = SEED\n",
        "    feature_importances = feature_importances.append(fi_tmp)\n",
        "    \n",
        "    ctb_val = model.predict(X_valid)\n",
        "    ctb_val = [1 if v >= 0.5 else 0 for v in ctb_val]\n",
        "    ctb_preds = model.predict(X_test)\n",
        "    \n",
        "    # 확률이 0.5보다 크면 1, 작으면 0으로 분류\n",
        "    acc_score = accuracy_score(y_valid, ctb_val)\n",
        "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "===== FOLD 0 =====\n",
            "0:\tlearn: 0.6880902\ttest: 0.6881691\tbest: 0.6881691 (0)\ttotal: 20.9ms\tremaining: 20.9s\n",
            "100:\tlearn: 0.4980864\ttest: 0.5026096\tbest: 0.5026096 (100)\ttotal: 2s\tremaining: 17.8s\n",
            "200:\tlearn: 0.4738206\ttest: 0.4815487\tbest: 0.4815487 (200)\ttotal: 3.92s\tremaining: 15.6s\n",
            "300:\tlearn: 0.4671748\ttest: 0.4773983\tbest: 0.4773983 (300)\ttotal: 5.79s\tremaining: 13.4s\n",
            "400:\tlearn: 0.4635072\ttest: 0.4757634\tbest: 0.4757634 (400)\ttotal: 7.6s\tremaining: 11.4s\n",
            "500:\tlearn: 0.4606957\ttest: 0.4749810\tbest: 0.4749810 (500)\ttotal: 9.37s\tremaining: 9.34s\n",
            "600:\tlearn: 0.4582118\ttest: 0.4745424\tbest: 0.4745424 (600)\ttotal: 11.2s\tremaining: 7.43s\n",
            "700:\tlearn: 0.4560348\ttest: 0.4743112\tbest: 0.4743036 (699)\ttotal: 13s\tremaining: 5.54s\n",
            "800:\tlearn: 0.4538536\ttest: 0.4741119\tbest: 0.4741119 (800)\ttotal: 14.8s\tremaining: 3.68s\n",
            "900:\tlearn: 0.4517912\ttest: 0.4740388\tbest: 0.4740388 (900)\ttotal: 16.6s\tremaining: 1.82s\n",
            "999:\tlearn: 0.4498273\ttest: 0.4740169\tbest: 0.4740007 (988)\ttotal: 18.4s\tremaining: 0us\n",
            "bestTest = 0.4740006836\n",
            "bestIteration = 988\n",
            "Shrink model to first 989 iterations.\n",
            "===== ACCURACY SCORE 0.777800 =====\n",
            "\n",
            "===== FOLD 1 =====\n",
            "0:\tlearn: 0.6881300\ttest: 0.6880576\tbest: 0.6880576 (0)\ttotal: 16ms\tremaining: 16s\n",
            "100:\tlearn: 0.4989163\ttest: 0.4959821\tbest: 0.4959821 (100)\ttotal: 1.59s\tremaining: 14.1s\n",
            "200:\tlearn: 0.4749076\ttest: 0.4724405\tbest: 0.4724405 (200)\ttotal: 3.14s\tremaining: 12.5s\n",
            "300:\tlearn: 0.4683574\ttest: 0.4675409\tbest: 0.4675409 (300)\ttotal: 4.79s\tremaining: 11.1s\n",
            "400:\tlearn: 0.4645832\ttest: 0.4656611\tbest: 0.4656611 (400)\ttotal: 6.4s\tremaining: 9.56s\n",
            "500:\tlearn: 0.4619176\ttest: 0.4649286\tbest: 0.4649257 (499)\ttotal: 8.03s\tremaining: 8s\n",
            "600:\tlearn: 0.4594914\ttest: 0.4644926\tbest: 0.4644926 (600)\ttotal: 9.7s\tremaining: 6.44s\n",
            "700:\tlearn: 0.4571511\ttest: 0.4641528\tbest: 0.4641524 (698)\ttotal: 11.4s\tremaining: 4.85s\n",
            "800:\tlearn: 0.4550386\ttest: 0.4637994\tbest: 0.4637994 (800)\ttotal: 13.1s\tremaining: 3.25s\n",
            "900:\tlearn: 0.4530399\ttest: 0.4636459\tbest: 0.4636180 (872)\ttotal: 14.7s\tremaining: 1.62s\n",
            "999:\tlearn: 0.4510975\ttest: 0.4633528\tbest: 0.4633345 (994)\ttotal: 16.4s\tremaining: 0us\n",
            "bestTest = 0.4633344727\n",
            "bestIteration = 994\n",
            "Shrink model to first 995 iterations.\n",
            "===== ACCURACY SCORE 0.789400 =====\n",
            "\n",
            "===== FOLD 2 =====\n",
            "0:\tlearn: 0.6881059\ttest: 0.6881238\tbest: 0.6881238 (0)\ttotal: 23.7ms\tremaining: 23.7s\n",
            "100:\tlearn: 0.4981544\ttest: 0.5012896\tbest: 0.5012896 (100)\ttotal: 1.58s\tremaining: 14.1s\n",
            "200:\tlearn: 0.4742738\ttest: 0.4797444\tbest: 0.4797444 (200)\ttotal: 3.13s\tremaining: 12.5s\n",
            "300:\tlearn: 0.4676937\ttest: 0.4750119\tbest: 0.4750119 (300)\ttotal: 4.69s\tremaining: 10.9s\n",
            "400:\tlearn: 0.4639237\ttest: 0.4733896\tbest: 0.4733896 (400)\ttotal: 6.28s\tremaining: 9.38s\n",
            "500:\tlearn: 0.4611892\ttest: 0.4725551\tbest: 0.4725537 (499)\ttotal: 7.85s\tremaining: 7.81s\n",
            "600:\tlearn: 0.4586559\ttest: 0.4720804\tbest: 0.4720804 (600)\ttotal: 9.41s\tremaining: 6.25s\n",
            "700:\tlearn: 0.4563816\ttest: 0.4716680\tbest: 0.4716680 (700)\ttotal: 11s\tremaining: 4.68s\n",
            "800:\tlearn: 0.4542226\ttest: 0.4713257\tbest: 0.4713257 (800)\ttotal: 12.5s\tremaining: 3.11s\n",
            "900:\tlearn: 0.4521395\ttest: 0.4710861\tbest: 0.4710659 (895)\ttotal: 14.1s\tremaining: 1.54s\n",
            "999:\tlearn: 0.4500953\ttest: 0.4709599\tbest: 0.4709588 (995)\ttotal: 15.6s\tremaining: 0us\n",
            "bestTest = 0.4709588379\n",
            "bestIteration = 995\n",
            "Shrink model to first 996 iterations.\n",
            "===== ACCURACY SCORE 0.782200 =====\n",
            "\n",
            "===== FOLD 3 =====\n",
            "0:\tlearn: 0.6882078\ttest: 0.6883021\tbest: 0.6883021 (0)\ttotal: 16.9ms\tremaining: 16.9s\n",
            "100:\tlearn: 0.4979871\ttest: 0.5028308\tbest: 0.5028308 (100)\ttotal: 1.62s\tremaining: 14.4s\n",
            "200:\tlearn: 0.4735658\ttest: 0.4813346\tbest: 0.4813346 (200)\ttotal: 3.24s\tremaining: 12.9s\n",
            "300:\tlearn: 0.4670189\ttest: 0.4775058\tbest: 0.4775058 (300)\ttotal: 4.84s\tremaining: 11.2s\n",
            "400:\tlearn: 0.4633845\ttest: 0.4759800\tbest: 0.4759800 (400)\ttotal: 6.45s\tremaining: 9.63s\n",
            "500:\tlearn: 0.4605947\ttest: 0.4752760\tbest: 0.4752503 (497)\ttotal: 8.03s\tremaining: 8s\n",
            "600:\tlearn: 0.4582125\ttest: 0.4748088\tbest: 0.4748039 (598)\ttotal: 9.61s\tremaining: 6.38s\n",
            "700:\tlearn: 0.4559171\ttest: 0.4744564\tbest: 0.4744564 (700)\ttotal: 11.2s\tremaining: 4.78s\n",
            "800:\tlearn: 0.4538520\ttest: 0.4742826\tbest: 0.4742826 (800)\ttotal: 12.8s\tremaining: 3.18s\n",
            "900:\tlearn: 0.4517743\ttest: 0.4741363\tbest: 0.4741323 (898)\ttotal: 14.3s\tremaining: 1.57s\n",
            "999:\tlearn: 0.4498289\ttest: 0.4741123\tbest: 0.4740611 (940)\ttotal: 15.9s\tremaining: 0us\n",
            "bestTest = 0.4740611328\n",
            "bestIteration = 940\n",
            "Shrink model to first 941 iterations.\n",
            "===== ACCURACY SCORE 0.784000 =====\n",
            "\n",
            "===== FOLD 4 =====\n",
            "0:\tlearn: 0.6880971\ttest: 0.6881527\tbest: 0.6881527 (0)\ttotal: 16.5ms\tremaining: 16.5s\n",
            "100:\tlearn: 0.4981149\ttest: 0.5015989\tbest: 0.5015989 (100)\ttotal: 1.56s\tremaining: 13.9s\n",
            "200:\tlearn: 0.4741430\ttest: 0.4799518\tbest: 0.4799518 (200)\ttotal: 3.21s\tremaining: 12.7s\n",
            "300:\tlearn: 0.4675249\ttest: 0.4756741\tbest: 0.4756741 (300)\ttotal: 4.86s\tremaining: 11.3s\n",
            "400:\tlearn: 0.4639340\ttest: 0.4740664\tbest: 0.4740644 (399)\ttotal: 6.46s\tremaining: 9.64s\n",
            "500:\tlearn: 0.4612419\ttest: 0.4733748\tbest: 0.4733748 (500)\ttotal: 8.03s\tremaining: 8s\n",
            "600:\tlearn: 0.4586678\ttest: 0.4727742\tbest: 0.4727742 (600)\ttotal: 9.65s\tremaining: 6.41s\n",
            "700:\tlearn: 0.4564275\ttest: 0.4724875\tbest: 0.4724713 (684)\ttotal: 11.2s\tremaining: 4.79s\n",
            "800:\tlearn: 0.4541346\ttest: 0.4721015\tbest: 0.4720914 (798)\ttotal: 12.8s\tremaining: 3.18s\n",
            "900:\tlearn: 0.4521999\ttest: 0.4719964\tbest: 0.4719722 (841)\ttotal: 14.5s\tremaining: 1.59s\n",
            "999:\tlearn: 0.4502276\ttest: 0.4720346\tbest: 0.4719583 (907)\ttotal: 16.1s\tremaining: 0us\n",
            "bestTest = 0.4719583008\n",
            "bestIteration = 907\n",
            "Shrink model to first 908 iterations.\n",
            "===== ACCURACY SCORE 0.781900 =====\n",
            "\n",
            "===== FOLD 5 =====\n",
            "0:\tlearn: 0.6881096\ttest: 0.6881271\tbest: 0.6881271 (0)\ttotal: 16.3ms\tremaining: 16.3s\n",
            "100:\tlearn: 0.4986176\ttest: 0.4994778\tbest: 0.4994778 (100)\ttotal: 1.58s\tremaining: 14s\n",
            "200:\tlearn: 0.4746106\ttest: 0.4769361\tbest: 0.4769361 (200)\ttotal: 3.18s\tremaining: 12.6s\n",
            "300:\tlearn: 0.4679592\ttest: 0.4723332\tbest: 0.4723332 (300)\ttotal: 4.74s\tremaining: 11s\n",
            "400:\tlearn: 0.4642214\ttest: 0.4702781\tbest: 0.4702781 (400)\ttotal: 6.3s\tremaining: 9.42s\n",
            "500:\tlearn: 0.4614493\ttest: 0.4692066\tbest: 0.4692066 (500)\ttotal: 7.86s\tremaining: 7.83s\n",
            "600:\tlearn: 0.4589703\ttest: 0.4685321\tbest: 0.4685321 (600)\ttotal: 9.44s\tremaining: 6.27s\n",
            "700:\tlearn: 0.4566529\ttest: 0.4681446\tbest: 0.4681446 (700)\ttotal: 11s\tremaining: 4.7s\n",
            "800:\tlearn: 0.4545557\ttest: 0.4677990\tbest: 0.4677836 (797)\ttotal: 12.6s\tremaining: 3.12s\n",
            "900:\tlearn: 0.4524201\ttest: 0.4675636\tbest: 0.4675622 (886)\ttotal: 14.1s\tremaining: 1.55s\n",
            "999:\tlearn: 0.4505199\ttest: 0.4674582\tbest: 0.4674534 (995)\ttotal: 15.7s\tremaining: 0us\n",
            "bestTest = 0.467453418\n",
            "bestIteration = 995\n",
            "Shrink model to first 996 iterations.\n",
            "===== ACCURACY SCORE 0.783000 =====\n",
            "\n",
            "===== FOLD 6 =====\n",
            "0:\tlearn: 0.6881331\ttest: 0.6880648\tbest: 0.6880648 (0)\ttotal: 24.1ms\tremaining: 24.1s\n",
            "100:\tlearn: 0.4990969\ttest: 0.4952566\tbest: 0.4952566 (100)\ttotal: 1.57s\tremaining: 14s\n",
            "200:\tlearn: 0.4750982\ttest: 0.4717889\tbest: 0.4717889 (200)\ttotal: 3.15s\tremaining: 12.5s\n",
            "300:\tlearn: 0.4683937\ttest: 0.4668112\tbest: 0.4668112 (300)\ttotal: 4.78s\tremaining: 11.1s\n",
            "400:\tlearn: 0.4647999\ttest: 0.4649636\tbest: 0.4649636 (400)\ttotal: 6.42s\tremaining: 9.59s\n",
            "500:\tlearn: 0.4621077\ttest: 0.4640250\tbest: 0.4640250 (500)\ttotal: 7.93s\tremaining: 7.89s\n",
            "600:\tlearn: 0.4597560\ttest: 0.4634685\tbest: 0.4634632 (598)\ttotal: 9.46s\tremaining: 6.28s\n",
            "700:\tlearn: 0.4574554\ttest: 0.4631834\tbest: 0.4631834 (700)\ttotal: 11s\tremaining: 4.68s\n",
            "800:\tlearn: 0.4552867\ttest: 0.4630369\tbest: 0.4630340 (794)\ttotal: 12.5s\tremaining: 3.1s\n",
            "900:\tlearn: 0.4532141\ttest: 0.4629471\tbest: 0.4629141 (884)\ttotal: 14s\tremaining: 1.54s\n",
            "999:\tlearn: 0.4513721\ttest: 0.4628353\tbest: 0.4628353 (999)\ttotal: 15.5s\tremaining: 0us\n",
            "bestTest = 0.4628352539\n",
            "bestIteration = 999\n",
            "===== ACCURACY SCORE 0.785500 =====\n",
            "\n",
            "===== FOLD 7 =====\n",
            "0:\tlearn: 0.6882170\ttest: 0.6881963\tbest: 0.6881963 (0)\ttotal: 15.8ms\tremaining: 15.8s\n",
            "100:\tlearn: 0.4988684\ttest: 0.4960583\tbest: 0.4960583 (100)\ttotal: 1.54s\tremaining: 13.7s\n",
            "200:\tlearn: 0.4749194\ttest: 0.4729896\tbest: 0.4729896 (200)\ttotal: 3.14s\tremaining: 12.5s\n",
            "300:\tlearn: 0.4682145\ttest: 0.4681887\tbest: 0.4681887 (300)\ttotal: 4.71s\tremaining: 10.9s\n",
            "400:\tlearn: 0.4646228\ttest: 0.4666570\tbest: 0.4666570 (400)\ttotal: 6.3s\tremaining: 9.41s\n",
            "500:\tlearn: 0.4618722\ttest: 0.4659749\tbest: 0.4659749 (500)\ttotal: 7.92s\tremaining: 7.89s\n",
            "600:\tlearn: 0.4593883\ttest: 0.4656352\tbest: 0.4656352 (600)\ttotal: 9.5s\tremaining: 6.3s\n",
            "700:\tlearn: 0.4570076\ttest: 0.4654781\tbest: 0.4654730 (694)\ttotal: 11.1s\tremaining: 4.72s\n",
            "800:\tlearn: 0.4548742\ttest: 0.4652956\tbest: 0.4652519 (789)\ttotal: 12.7s\tremaining: 3.16s\n",
            "900:\tlearn: 0.4527868\ttest: 0.4652253\tbest: 0.4651877 (891)\ttotal: 14.3s\tremaining: 1.57s\n",
            "bestTest = 0.4651876953\n",
            "bestIteration = 891\n",
            "Shrink model to first 892 iterations.\n",
            "===== ACCURACY SCORE 0.789000 =====\n",
            "\n",
            "===== FOLD 8 =====\n",
            "0:\tlearn: 0.6880837\ttest: 0.6882283\tbest: 0.6882283 (0)\ttotal: 24.7ms\tremaining: 24.6s\n",
            "100:\tlearn: 0.4975289\ttest: 0.5050906\tbest: 0.5050906 (100)\ttotal: 1.59s\tremaining: 14.1s\n",
            "200:\tlearn: 0.4734300\ttest: 0.4846668\tbest: 0.4846668 (200)\ttotal: 3.15s\tremaining: 12.5s\n",
            "300:\tlearn: 0.4668859\ttest: 0.4806457\tbest: 0.4806457 (300)\ttotal: 4.69s\tremaining: 10.9s\n",
            "400:\tlearn: 0.4631597\ttest: 0.4790337\tbest: 0.4790337 (400)\ttotal: 6.24s\tremaining: 9.32s\n",
            "500:\tlearn: 0.4603869\ttest: 0.4781687\tbest: 0.4781687 (500)\ttotal: 7.82s\tremaining: 7.78s\n",
            "600:\tlearn: 0.4579437\ttest: 0.4777573\tbest: 0.4777552 (599)\ttotal: 9.33s\tremaining: 6.19s\n",
            "700:\tlearn: 0.4556929\ttest: 0.4773979\tbest: 0.4773874 (698)\ttotal: 10.9s\tremaining: 4.64s\n",
            "800:\tlearn: 0.4534393\ttest: 0.4771108\tbest: 0.4770986 (789)\ttotal: 12.4s\tremaining: 3.08s\n",
            "900:\tlearn: 0.4513535\ttest: 0.4768384\tbest: 0.4768347 (898)\ttotal: 13.9s\tremaining: 1.53s\n",
            "999:\tlearn: 0.4493935\ttest: 0.4767284\tbest: 0.4767228 (998)\ttotal: 15.4s\tremaining: 0us\n",
            "bestTest = 0.4767227539\n",
            "bestIteration = 998\n",
            "Shrink model to first 999 iterations.\n",
            "===== ACCURACY SCORE 0.776900 =====\n",
            "\n",
            "===== FOLD 9 =====\n",
            "0:\tlearn: 0.6881102\ttest: 0.6881753\tbest: 0.6881753 (0)\ttotal: 23.4ms\tremaining: 23.4s\n",
            "100:\tlearn: 0.4979105\ttest: 0.5021139\tbest: 0.5021139 (100)\ttotal: 1.6s\tremaining: 14.2s\n",
            "200:\tlearn: 0.4737674\ttest: 0.4806308\tbest: 0.4806308 (200)\ttotal: 3.17s\tremaining: 12.6s\n",
            "300:\tlearn: 0.4672159\ttest: 0.4764905\tbest: 0.4764905 (300)\ttotal: 4.72s\tremaining: 11s\n",
            "400:\tlearn: 0.4634322\ttest: 0.4748731\tbest: 0.4748731 (400)\ttotal: 6.23s\tremaining: 9.3s\n",
            "500:\tlearn: 0.4606546\ttest: 0.4741420\tbest: 0.4741420 (500)\ttotal: 7.77s\tremaining: 7.74s\n",
            "600:\tlearn: 0.4582562\ttest: 0.4736163\tbest: 0.4736079 (586)\ttotal: 9.32s\tremaining: 6.18s\n",
            "700:\tlearn: 0.4560577\ttest: 0.4733832\tbest: 0.4733832 (700)\ttotal: 10.9s\tremaining: 4.64s\n",
            "800:\tlearn: 0.4539784\ttest: 0.4731133\tbest: 0.4731133 (800)\ttotal: 12.4s\tremaining: 3.09s\n",
            "900:\tlearn: 0.4519223\ttest: 0.4729028\tbest: 0.4728967 (888)\ttotal: 14.1s\tremaining: 1.55s\n",
            "999:\tlearn: 0.4499837\ttest: 0.4728704\tbest: 0.4728670 (990)\ttotal: 15.7s\tremaining: 0us\n",
            "bestTest = 0.4728669922\n",
            "bestIteration = 990\n",
            "Shrink model to first 991 iterations.\n",
            "===== ACCURACY SCORE 0.779400 =====\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UyyFnD8s9P8"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "9_R_e7H4s9lH",
        "outputId": "7507f362-6364-4ebc-f3ba-0555288c3724"
      },
      "source": [
        "order = list(feature_importances.groupby(\"feature\").mean()\\\n",
        "             .sort_values(\"importance\", ascending=False).index)\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importances, order=order)\n",
        "plt.title(\"{} importance\".format(\"CatBoostClassifier\"))\n",
        "plt.tight_layout()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7jkH3O9tO4o"
      },
      "source": [
        "## DecisionTreeModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4rAzUtf3tQew",
        "outputId": "86276072-652c-4c5b-c7a9-d862d0eb1383"
      },
      "source": [
        "parameters = {\n",
        "    'max_depth': np.arange(2, 5, dtype=int),\n",
        "    'min_samples_leaf': np.arange(2, 5, dtype=int)\n",
        "}\n",
        "\n",
        "classifier = DecisionTreeClassifier(random_state=2021)\n",
        "\n",
        "model = GridSearchCV(\n",
        "    estimator = classifier,\n",
        "    param_grid = parameters,\n",
        "    scoring = 'accuracy',\n",
        "    cv = 10,\n",
        "    n_jobs = -1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "best_parameters = model.best_params_\n",
        "print(best_parameters)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'max_depth': 4, 'min_samples_leaf': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "_DoHHeoStuRZ",
        "outputId": "d2d8cf96-da49-4313-dd9b-ad9e940fbf82"
      },
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "\n",
        "skf = StratifiedKFold(n_splits=N_SPLIT, shuffle=True, random_state=SEED)\n",
        "\n",
        "for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df2, train_df2[TARGET])):\n",
        "    print(f'===== FOLD {fold} =====')\n",
        "\n",
        "    X_train, y_train = train_df2.iloc[train_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[train_idx][TARGET]\n",
        "    X_valid, y_valid = train_df2.iloc[valid_idx].drop(TARGET, axis=1),\\\n",
        "    train_df.iloc[valid_idx][TARGET]\n",
        "\n",
        "    model = DecisionTreeClassifier(\n",
        "        max_depth = best_parameters['max_depth'],\n",
        "        min_samples_leaf = best_parameters['min_samples_leaf'],\n",
        "        random_state = SEED\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    dtm_val = model.predict(X_valid)\n",
        "    dtm_val = [1 if v >= 0.5 else 0 for v in dtm_val]\n",
        "    dtm_preds = model.predict(X_test)\n",
        "\n",
        "    \n",
        "    # 확률이 0.5보다 크면 1, 작으면 0으로 분류\n",
        "    acc_score = accuracy_score(y_valid, dtm_val)\n",
        "    print(f\"===== ACCURACY SCORE {acc_score:.6f} =====\\n\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "===== FOLD 0 =====\n",
            "===== ACCURACY SCORE 0.766600 =====\n",
            "\n",
            "===== FOLD 1 =====\n",
            "===== ACCURACY SCORE 0.783400 =====\n",
            "\n",
            "===== FOLD 2 =====\n",
            "===== ACCURACY SCORE 0.771000 =====\n",
            "\n",
            "===== FOLD 3 =====\n",
            "===== ACCURACY SCORE 0.770500 =====\n",
            "\n",
            "===== FOLD 4 =====\n",
            "===== ACCURACY SCORE 0.771200 =====\n",
            "\n",
            "===== FOLD 5 =====\n",
            "===== ACCURACY SCORE 0.772100 =====\n",
            "\n",
            "===== FOLD 6 =====\n",
            "===== ACCURACY SCORE 0.777900 =====\n",
            "\n",
            "===== FOLD 7 =====\n",
            "===== ACCURACY SCORE 0.781300 =====\n",
            "\n",
            "===== FOLD 8 =====\n",
            "===== ACCURACY SCORE 0.771300 =====\n",
            "\n",
            "===== FOLD 9 =====\n",
            "===== ACCURACY SCORE 0.772900 =====\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnDlaa-0wYkA"
      },
      "source": [
        "### Plot Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "pQjfAYW4wYA-",
        "outputId": "3b184393-46e7-4a28-b121-e018a835ca82"
      },
      "source": [
        "dot_data = export_graphviz(\n",
        "    model,\n",
        "    out_file = None,\n",
        "    feature_names = X_train.columns,\n",
        "    class_names = ['0', '1'],\n",
        "    filled = True,\n",
        "    rounded = False,\n",
        "    special_characters = True,\n",
        "    precision = 3\n",
        ")\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fe7f1bb8e90>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"2373pt\" height=\"552pt\"\n viewBox=\"0.00 0.00 2373.00 552.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 548)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-548 2369,-548 2369,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"#f8dfcd\" stroke=\"#000000\" points=\"1261.5,-544 1106.5,-544 1106.5,-461 1261.5,-461 1261.5,-544\"/>\n<text text-anchor=\"start\" x=\"1156\" y=\"-528.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Sex ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1151.5\" y=\"-513.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"1134.5\" y=\"-498.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 90000</text>\n<text text-anchor=\"start\" x=\"1114.5\" y=\"-483.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [51503, 38497]</text>\n<text text-anchor=\"start\" x=\"1159\" y=\"-468.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"#89c5f0\" stroke=\"#000000\" points=\"984,-425 830,-425 830,-342 984,-342 984,-425\"/>\n<text text-anchor=\"start\" x=\"851.5\" y=\"-409.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"874.5\" y=\"-394.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.41</text>\n<text text-anchor=\"start\" x=\"857.5\" y=\"-379.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 39527</text>\n<text text-anchor=\"start\" x=\"838\" y=\"-364.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [11394, 28133]</text>\n<text text-anchor=\"start\" x=\"882\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1106.4717,-469.1936C1071.3573,-454.1084 1029.71,-436.2166 993.5761,-420.6934\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"994.5994,-417.3237 984.0298,-416.5922 991.8363,-423.7553 994.5994,-417.3237\"/>\n<text text-anchor=\"middle\" x=\"993.2944\" y=\"-436.1122\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<polygon fill=\"#eca26c\" stroke=\"#000000\" points=\"1548.5,-425 1393.5,-425 1393.5,-342 1548.5,-342 1548.5,-425\"/>\n<text text-anchor=\"start\" x=\"1416.5\" y=\"-409.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Embarked_S ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1434.5\" y=\"-394.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.326</text>\n<text text-anchor=\"start\" x=\"1421.5\" y=\"-379.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50473</text>\n<text text-anchor=\"start\" x=\"1401.5\" y=\"-364.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [40109, 10364]</text>\n<text text-anchor=\"start\" x=\"1446\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>0&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1261.6663,-470.2969C1299.3139,-454.6869 1344.6798,-435.8767 1383.5405,-419.7637\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1385.3747,-422.7922 1393.2716,-415.7289 1382.6936,-416.326 1385.3747,-422.7922\"/>\n<text text-anchor=\"middle\" x=\"1383.7128\" y=\"-435.1293\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"#abd5f4\" stroke=\"#000000\" points=\"528.5,-306 381.5,-306 381.5,-223 528.5,-223 528.5,-306\"/>\n<text text-anchor=\"start\" x=\"413\" y=\"-290.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pclass ≤ 0.302</text>\n<text text-anchor=\"start\" x=\"418.5\" y=\"-275.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.464</text>\n<text text-anchor=\"start\" x=\"406\" y=\"-260.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 25311</text>\n<text text-anchor=\"start\" x=\"389.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [9240, 16071]</text>\n<text text-anchor=\"start\" x=\"430\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M829.812,-363.1784C748.8041,-341.8511 621.877,-308.4344 538.5563,-286.4982\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"539.4316,-283.1095 528.87,-283.9481 537.6494,-289.8788 539.4316,-283.1095\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"#5cafea\" stroke=\"#000000\" points=\"980.5,-306 833.5,-306 833.5,-223 980.5,-223 980.5,-306\"/>\n<text text-anchor=\"start\" x=\"864\" y=\"-290.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Cabin_A ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"870.5\" y=\"-275.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.257</text>\n<text text-anchor=\"start\" x=\"857.5\" y=\"-260.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 14216</text>\n<text text-anchor=\"start\" x=\"841.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [2154, 12062]</text>\n<text text-anchor=\"start\" x=\"882\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 1&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>1&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M907,-341.8796C907,-333.6838 907,-324.9891 907,-316.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"910.5001,-316.298 907,-306.2981 903.5001,-316.2981 910.5001,-316.298\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"#8fc8f0\" stroke=\"#000000\" points=\"300,-187 154,-187 154,-104 300,-104 300,-187\"/>\n<text text-anchor=\"start\" x=\"184\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Cabin_A ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"190.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.422</text>\n<text text-anchor=\"start\" x=\"177.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 16481</text>\n<text text-anchor=\"start\" x=\"162\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4987, 11494]</text>\n<text text-anchor=\"start\" x=\"202\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M381.2898,-226.0284C358.2166,-213.9859 332.6164,-200.6243 309.0079,-188.3024\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"310.5513,-185.1599 300.0667,-183.6357 307.3124,-191.3655 310.5513,-185.1599\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"#f1f8fd\" stroke=\"#000000\" points=\"525,-187 385,-187 385,-104 525,-104 525,-187\"/>\n<text text-anchor=\"start\" x=\"420\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Ticket ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"418.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"409.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8830</text>\n<text text-anchor=\"start\" x=\"393\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4253, 4577]</text>\n<text text-anchor=\"start\" x=\"430\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M455,-222.8796C455,-214.6838 455,-205.9891 455,-197.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"458.5001,-197.298 455,-187.2981 451.5001,-197.2981 458.5001,-197.298\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"#84c2ef\" stroke=\"#000000\" points=\"146,-68 0,-68 0,0 146,0 146,-68\"/>\n<text text-anchor=\"start\" x=\"36.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.399</text>\n<text text-anchor=\"start\" x=\"23.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15216</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [4185, 11031]</text>\n<text text-anchor=\"start\" x=\"48\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M169.6561,-103.9815C156.2006,-94.2394 141.8869,-83.8759 128.5133,-74.193\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"130.4763,-71.2933 120.3238,-68.2637 126.3711,-76.9632 130.4763,-71.2933\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"#f4caab\" stroke=\"#000000\" points=\"289.5,-68 164.5,-68 164.5,0 289.5,0 289.5,-68\"/>\n<text text-anchor=\"start\" x=\"190.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.464</text>\n<text text-anchor=\"start\" x=\"181.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1265</text>\n<text text-anchor=\"start\" x=\"172.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [802, 463]</text>\n<text text-anchor=\"start\" x=\"202\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M227,-103.9815C227,-95.618 227,-86.7965 227,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.5001,-78.2636 227,-68.2637 223.5001,-78.2637 230.5001,-78.2636\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"#eeab7b\" stroke=\"#000000\" points=\"432.5,-68 307.5,-68 307.5,0 432.5,0 432.5,-68\"/>\n<text text-anchor=\"start\" x=\"333.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"328\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 555</text>\n<text text-anchor=\"start\" x=\"315.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [416, 139]</text>\n<text text-anchor=\"start\" x=\"345\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M423.3491,-103.9815C416.4829,-94.9747 409.2118,-85.4367 402.3202,-76.3965\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"404.9664,-74.0945 396.1203,-68.2637 399.3995,-78.3383 404.9664,-74.0945\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"#e4f2fb\" stroke=\"#000000\" points=\"591,-68 451,-68 451,0 591,0 591,-68\"/>\n<text text-anchor=\"start\" x=\"484.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.497</text>\n<text text-anchor=\"start\" x=\"475.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 8275</text>\n<text text-anchor=\"start\" x=\"459\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3837, 4438]</text>\n<text text-anchor=\"start\" x=\"496\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M479.576,-103.9815C484.7986,-95.1585 490.3229,-85.8258 495.5763,-76.9506\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"498.6364,-78.652 500.7184,-68.2637 492.6126,-75.0863 498.6364,-78.652\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"#58ade9\" stroke=\"#000000\" points=\"903,-187 757,-187 757,-104 903,-104 903,-187\"/>\n<text text-anchor=\"start\" x=\"788\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pclass ≤ 0.302</text>\n<text text-anchor=\"start\" x=\"793.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.236</text>\n<text text-anchor=\"start\" x=\"780.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 13663</text>\n<text text-anchor=\"start\" x=\"765\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1872, 11791]</text>\n<text text-anchor=\"start\" x=\"805\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M880.0691,-222.8796C874.4163,-214.1434 868.3967,-204.8404 862.5634,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"865.4169,-193.7924 857.0458,-187.2981 859.5399,-197.5952 865.4169,-193.7924\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<polygon fill=\"#fefaf7\" stroke=\"#000000\" points=\"1046.5,-187 921.5,-187 921.5,-104 1046.5,-104 1046.5,-187\"/>\n<text text-anchor=\"start\" x=\"935\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Name ≤ 25810.0</text>\n<text text-anchor=\"start\" x=\"955\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"942\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 553</text>\n<text text-anchor=\"start\" x=\"929.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [282, 271]</text>\n<text text-anchor=\"start\" x=\"959\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 9&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>9&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M933.9309,-222.8796C939.5837,-214.1434 945.6033,-204.8404 951.4366,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"954.4601,-197.5952 956.9542,-187.2981 948.5831,-193.7924 954.4601,-197.5952\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"#52aae8\" stroke=\"#000000\" points=\"749,-68 609,-68 609,0 749,0 749,-68\"/>\n<text text-anchor=\"start\" x=\"642.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.201</text>\n<text text-anchor=\"start\" x=\"630\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 11235</text>\n<text text-anchor=\"start\" x=\"617\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1271, 9964]</text>\n<text text-anchor=\"start\" x=\"654\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M773.7732,-103.9815C760.7043,-94.3313 746.8097,-84.0714 733.8032,-74.4673\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"735.5255,-71.3883 725.4019,-68.2637 731.3674,-77.0195 735.5255,-71.3883\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"#7abdee\" stroke=\"#000000\" points=\"899,-68 767,-68 767,0 899,0 899,-68\"/>\n<text text-anchor=\"start\" x=\"796.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.373</text>\n<text text-anchor=\"start\" x=\"787.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2428</text>\n<text text-anchor=\"start\" x=\"775\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [601, 1827]</text>\n<text text-anchor=\"start\" x=\"808\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 10&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>10&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M831.1171,-103.9815C831.3421,-95.618 831.5795,-86.7965 831.807,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"835.3078,-78.3542 832.0781,-68.2637 828.3103,-78.1659 835.3078,-78.3542\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<polygon fill=\"#fdf5ef\" stroke=\"#000000\" points=\"1042.5,-68 917.5,-68 917.5,0 1042.5,0 1042.5,-68\"/>\n<text text-anchor=\"start\" x=\"943.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"938\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 538</text>\n<text text-anchor=\"start\" x=\"925.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [280, 258]</text>\n<text text-anchor=\"start\" x=\"955\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M982.5105,-103.9815C982.2105,-95.618 981.894,-86.7965 981.5907,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"985.0855,-78.1317 981.2292,-68.2637 978.09,-78.3828 985.0855,-78.1317\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<polygon fill=\"#57ace9\" stroke=\"#000000\" points=\"1163,-68 1061,-68 1061,0 1163,0 1163,-68\"/>\n<text text-anchor=\"start\" x=\"1075.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.231</text>\n<text text-anchor=\"start\" x=\"1074\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15</text>\n<text text-anchor=\"start\" x=\"1069\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 13]</text>\n<text text-anchor=\"start\" x=\"1087\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 13&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>13&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1031.6625,-103.9815C1042.5297,-94.5151 1054.0705,-84.462 1064.9135,-75.0168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1067.4245,-77.4712 1072.6659,-68.2637 1062.8266,-72.1929 1067.4245,-77.4712\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<polygon fill=\"#fdf5ef\" stroke=\"#000000\" points=\"1541,-306 1401,-306 1401,-223 1541,-223 1541,-306\"/>\n<text text-anchor=\"start\" x=\"1429\" y=\"-290.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pclass ≤ 0.302</text>\n<text text-anchor=\"start\" x=\"1434.5\" y=\"-275.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"1425.5\" y=\"-260.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 7251</text>\n<text text-anchor=\"start\" x=\"1409\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3778, 3473]</text>\n<text text-anchor=\"start\" x=\"1446\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1471,-341.8796C1471,-333.6838 1471,-324.9891 1471,-316.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1474.5001,-316.298 1471,-306.2981 1467.5001,-316.2981 1474.5001,-316.298\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<polygon fill=\"#ea995f\" stroke=\"#000000\" points=\"1975.5,-306 1828.5,-306 1828.5,-223 1975.5,-223 1975.5,-306\"/>\n<text text-anchor=\"start\" x=\"1860\" y=\"-290.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Pclass ≤ 0.302</text>\n<text text-anchor=\"start\" x=\"1865.5\" y=\"-275.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.268</text>\n<text text-anchor=\"start\" x=\"1852.5\" y=\"-260.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 43222</text>\n<text text-anchor=\"start\" x=\"1836.5\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [36331, 6891]</text>\n<text text-anchor=\"start\" x=\"1877\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 16&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>16&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1548.5519,-362.0877C1624.6689,-341.0717 1740.3974,-309.1188 1818.5,-287.5545\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1819.601,-290.8816 1828.3088,-284.8463 1817.738,-284.134 1819.601,-290.8816\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<polygon fill=\"#dfeffb\" stroke=\"#000000\" points=\"1464,-187 1324,-187 1324,-104 1464,-104 1464,-187\"/>\n<text text-anchor=\"start\" x=\"1351\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Cabin_A ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1357.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.496</text>\n<text text-anchor=\"start\" x=\"1348.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5550</text>\n<text text-anchor=\"start\" x=\"1332\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [2529, 3021]</text>\n<text text-anchor=\"start\" x=\"1369\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 17&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>17&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1444.0691,-222.8796C1438.4163,-214.1434 1432.3967,-204.8404 1426.5634,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1429.4169,-193.7924 1421.0458,-187.2981 1423.5399,-197.5952 1429.4169,-193.7924\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<polygon fill=\"#eeaf81\" stroke=\"#000000\" points=\"1614,-187 1482,-187 1482,-104 1614,-104 1614,-187\"/>\n<text text-anchor=\"start\" x=\"1492.5\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1515.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.39</text>\n<text text-anchor=\"start\" x=\"1502.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1701</text>\n<text text-anchor=\"start\" x=\"1490\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1249, 452]</text>\n<text text-anchor=\"start\" x=\"1523\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 17&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>17&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1497.9309,-222.8796C1503.5837,-214.1434 1509.6033,-204.8404 1515.4366,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1518.4601,-197.5952 1520.9542,-187.2981 1512.5831,-193.7924 1518.4601,-197.5952\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<polygon fill=\"#c6e3f7\" stroke=\"#000000\" points=\"1321,-68 1181,-68 1181,0 1321,0 1321,-68\"/>\n<text text-anchor=\"start\" x=\"1214.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.486</text>\n<text text-anchor=\"start\" x=\"1205.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4754</text>\n<text text-anchor=\"start\" x=\"1189\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1976, 2778]</text>\n<text text-anchor=\"start\" x=\"1226\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 1</text>\n</g>\n<!-- 18&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>18&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1340.7521,-103.9815C1328.3756,-94.3313 1315.2172,-84.0714 1302.8997,-74.4673\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1304.9818,-71.6525 1294.9435,-68.2637 1300.6775,-77.1728 1304.9818,-71.6525\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<polygon fill=\"#f0b890\" stroke=\"#000000\" points=\"1464.5,-68 1339.5,-68 1339.5,0 1464.5,0 1464.5,-68\"/>\n<text text-anchor=\"start\" x=\"1365.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.424</text>\n<text text-anchor=\"start\" x=\"1360\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 796</text>\n<text text-anchor=\"start\" x=\"1347.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [553, 243]</text>\n<text text-anchor=\"start\" x=\"1377\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 18&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>18&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1396.9789,-103.9815C1397.579,-95.618 1398.2119,-86.7965 1398.8186,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1402.3169,-78.4885 1399.5416,-68.2637 1395.3349,-77.9875 1402.3169,-78.4885\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<polygon fill=\"#e99457\" stroke=\"#000000\" points=\"1599.5,-68 1482.5,-68 1482.5,0 1599.5,0 1599.5,-68\"/>\n<text text-anchor=\"start\" x=\"1504.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.227</text>\n<text text-anchor=\"start\" x=\"1499\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 405</text>\n<text text-anchor=\"start\" x=\"1490.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [352, 53]</text>\n<text text-anchor=\"start\" x=\"1516\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1545.3935,-103.9815C1544.8684,-95.618 1544.3146,-86.7965 1543.7837,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1547.2709,-78.0247 1543.1511,-68.2637 1540.2846,-78.4634 1547.2709,-78.0247\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<polygon fill=\"#f1b991\" stroke=\"#000000\" points=\"1742.5,-68 1617.5,-68 1617.5,0 1742.5,0 1742.5,-68\"/>\n<text text-anchor=\"start\" x=\"1643.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.426</text>\n<text text-anchor=\"start\" x=\"1634.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1296</text>\n<text text-anchor=\"start\" x=\"1625.5\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [897, 399]</text>\n<text text-anchor=\"start\" x=\"1655\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 21&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>21&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1597.1519,-103.9815C1608.4676,-94.4232 1620.4913,-84.2668 1631.7675,-74.7419\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1634.0559,-77.3904 1639.4367,-68.2637 1629.5388,-72.0429 1634.0559,-77.3904\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<polygon fill=\"#eda978\" stroke=\"#000000\" points=\"1975.5,-187 1828.5,-187 1828.5,-104 1975.5,-104 1975.5,-187\"/>\n<text text-anchor=\"start\" x=\"1862.5\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Fare ≤ &#45;0.591</text>\n<text text-anchor=\"start\" x=\"1865.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.365</text>\n<text text-anchor=\"start\" x=\"1852.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19316</text>\n<text text-anchor=\"start\" x=\"1836.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [14678, 4638]</text>\n<text text-anchor=\"start\" x=\"1877\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 24&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>24&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1902,-222.8796C1902,-214.6838 1902,-205.9891 1902,-197.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1905.5001,-197.298 1902,-187.2981 1898.5001,-197.2981 1905.5001,-197.298\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<polygon fill=\"#e88e4e\" stroke=\"#000000\" points=\"2215.5,-187 2068.5,-187 2068.5,-104 2215.5,-104 2215.5,-187\"/>\n<text text-anchor=\"start\" x=\"2101\" y=\"-171.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Parch ≤ 0.028</text>\n<text text-anchor=\"start\" x=\"2105.5\" y=\"-156.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.171</text>\n<text text-anchor=\"start\" x=\"2092.5\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 23906</text>\n<text text-anchor=\"start\" x=\"2076.5\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [21653, 2253]</text>\n<text text-anchor=\"start\" x=\"2117\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 24&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>24&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1975.6389,-227.9874C2002.0076,-214.9129 2031.9056,-200.0885 2059.0108,-186.6488\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2060.6825,-189.7266 2068.0868,-182.1486 2057.5729,-183.4552 2060.6825,-189.7266\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<polygon fill=\"#ea985c\" stroke=\"#000000\" points=\"1893,-68 1761,-68 1761,0 1893,0 1893,-68\"/>\n<text text-anchor=\"start\" x=\"1790.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.257</text>\n<text text-anchor=\"start\" x=\"1781.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6465</text>\n<text text-anchor=\"start\" x=\"1769\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5484, 981]</text>\n<text text-anchor=\"start\" x=\"1802\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 25&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>25&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1874.0728,-103.9815C1868.0762,-95.0666 1861.7296,-85.6313 1855.7041,-76.6734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1858.5328,-74.6078 1850.0473,-68.2637 1852.7245,-78.5147 1858.5328,-74.6078\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<polygon fill=\"#efb388\" stroke=\"#000000\" points=\"2051,-68 1911,-68 1911,0 2051,0 2051,-68\"/>\n<text text-anchor=\"start\" x=\"1944.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.407</text>\n<text text-anchor=\"start\" x=\"1931.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 12851</text>\n<text text-anchor=\"start\" x=\"1919\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [9194, 3657]</text>\n<text text-anchor=\"start\" x=\"1956\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 25&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>25&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M1931.4167,-103.9815C1937.7331,-95.0666 1944.4182,-85.6313 1950.7651,-76.6734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1953.7981,-78.4466 1956.7235,-68.2637 1948.0864,-74.3998 1953.7981,-78.4466\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<polygon fill=\"#e78c4b\" stroke=\"#000000\" points=\"2215,-68 2069,-68 2069,0 2215,0 2215,-68\"/>\n<text text-anchor=\"start\" x=\"2105.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.152</text>\n<text text-anchor=\"start\" x=\"2092.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 19972</text>\n<text text-anchor=\"start\" x=\"2077\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [18311, 1661]</text>\n<text text-anchor=\"start\" x=\"2117\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 28&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>28&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2142,-103.9815C2142,-95.618 2142,-86.7965 2142,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2145.5001,-78.2636 2142,-68.2637 2138.5001,-78.2637 2145.5001,-78.2636\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<polygon fill=\"#ea975c\" stroke=\"#000000\" points=\"2365,-68 2233,-68 2233,0 2365,0 2365,-68\"/>\n<text text-anchor=\"start\" x=\"2262.5\" y=\"-52.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.256</text>\n<text text-anchor=\"start\" x=\"2253.5\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3934</text>\n<text text-anchor=\"start\" x=\"2241\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3342, 592]</text>\n<text text-anchor=\"start\" x=\"2274\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">class = 0</text>\n</g>\n<!-- 28&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>28&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M2200.461,-103.9815C2214.2508,-94.1881 2228.9247,-83.7668 2242.6205,-74.0402\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"2244.8785,-76.7295 2251.005,-68.0856 2240.8253,-71.0223 2244.8785,-76.7295\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXEQ8Acwwp39"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "o1oteBFmwqKS",
        "outputId": "9875b098-fe1a-4a1f-9ed1-78e9f6f893b1"
      },
      "source": [
        "submission_df['submit_lgb'] = [1 if pred >= 0.5 else 0 for pred in lgb_preds]\n",
        "submission_df['submit_ctb'] = [1 if pred >= 0.5 else 0 for pred in ctb_preds]\n",
        "submission_df['submit_dtm'] = [1 if pred >= 0.5 else 0 for pred in dtm_preds]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "jywozOfj1RTh",
        "outputId": "1eb35c19-cccc-4426-e2ab-d3bd9ded0dee"
      },
      "source": [
        "submission_df"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>submit_lgb</th>\n",
              "      <th>submit_ctb</th>\n",
              "      <th>submit_dtm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100001</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100002</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100004</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>199995</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>199996</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>199997</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>199998</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>199999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId  Survived  submit_lgb  submit_ctb  submit_dtm\n",
              "0           100000         0           0           0           0\n",
              "1           100001         1           1           1           1\n",
              "2           100002         1           1           1           1\n",
              "3           100003         0           0           0           0\n",
              "4           100004         1           1           1           1\n",
              "...            ...       ...         ...         ...         ...\n",
              "99995       199995         1           1           1           1\n",
              "99996       199996         0           0           0           0\n",
              "99997       199997         0           0           0           0\n",
              "99998       199998         1           1           1           1\n",
              "99999       199999         1           1           1           1\n",
              "\n",
              "[100000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "VsOsxxeixDaJ",
        "outputId": "7273ce6b-e8ba-45c5-c84d-8ffc08aee866"
      },
      "source": [
        "# 세 모델의 행 별로 생존자의 수를 더함\n",
        "# 0은 모두 사망으로 예측, 1은 하나만, 2는 두 모델, 3은 세 모델이 모두 생존으로 예측\n",
        "submission_df[[col for col in submission_df.columns if col.startswith('submit_')]]\\\n",
        ".sum(axis=1).value_counts()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    63505\n",
              "3    29359\n",
              "1     4760\n",
              "2     2376\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xNSHXgZFypsn",
        "outputId": "3abf67e6-c6f6-432a-b12a-b39bf81e5259"
      },
      "source": [
        "# 합이 2보다 크면 True -> int로 변환 (1)\n",
        "submission_df[TARGET] = (submission_df[[col for col in submission_df.columns\\\n",
        "                                  if col.startswith('submit_')]].sum(axis=1) >= 2)\\\n",
        "                                  .astype(int)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "nIORpSBv2wk1",
        "outputId": "d0be96c5-5657-458a-dbfd-3afd6f8f32ec"
      },
      "source": [
        "submission_df.drop([col for col in submission_df.columns if col.startswith('submit_')],\\\n",
        "                 axis=1, inplace=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Zv_RFdiA1EA4",
        "outputId": "09e1ad1d-18fc-4c93-cb10-c9af677c1126"
      },
      "source": [
        "submission_df.to_csv('Apr_Ensemble.csv', index=False)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bva8jI6q4la9"
      },
      "source": [
        "score: 0.80305, 369등"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1WUlEkD68hZ"
      },
      "source": [
        "## Pseudo labeling을 통한 모델 성능 향상"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcuuAqKz68DG"
      },
      "source": [
        "- 라벨링되지 않은 데이터(예를 들어 test 데이터 셋)을 1차적으로 학습된 모델을 이용하여 예측을 수행\n",
        "- 수도 레이블링을 한 후에, train 데이터 셋과 합친 큰 데이터셋을 이용하여 2차 학습 수행\n",
        "- 조건:\n",
        "    1. 수도 레이블링을 할 때 이용할 학습된 모델의 성능이 어느정도 좋아야함\n",
        "    2. 수도 레이블링 데이터 셋과 기존의 데이터 셋의 크기가 50대 50을 넘으면 안됨\n",
        "        - 진짜 label에서 많이 학습하고 pseudo label로 finetuning될 수 있게끔\n",
        "    3. \n"
      ]
    }
  ]
}